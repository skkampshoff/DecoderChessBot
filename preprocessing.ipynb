{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7b5565",
   "metadata": {},
   "source": [
    "# Bringing in Lichess Data and translating into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6185072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed a game.\n"
     ]
    }
   ],
   "source": [
    "import chess.pgn\n",
    "\n",
    "def test_pgn_file(pgn_file):\n",
    "    try:\n",
    "        with open(pgn_file) as f:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                print(\"No valid games in file.\")\n",
    "            else:\n",
    "                print(\"Successfully parsed a game.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PGN file: {e}\")\n",
    "\n",
    "# Run the test\n",
    "test_pgn_file(\"data/lichess_db_standard_rated_2023-07.pgn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976dae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid games in file: 21005010\n"
     ]
    }
   ],
   "source": [
    "import chess.pgn\n",
    "\n",
    "def count_valid_games(pgn_file):\n",
    "    count = 0\n",
    "    try:\n",
    "        with open(pgn_file) as f:\n",
    "            while True:\n",
    "                game = chess.pgn.read_game(f)\n",
    "                if game is None:\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "        print(f\"Total valid games in file: {count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PGN file: {e}\")\n",
    "\n",
    "# Run the test\n",
    "count_valid_games(\"data/lichess_db_standard_rated_2023-07.pgn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefc2f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 games...\n",
      "Processed 20000 games...\n",
      "Processed 30000 games...\n",
      "Processed 40000 games...\n",
      "Processed 50000 games...\n",
      "Processed 60000 games...\n",
      "Processed 70000 games...\n",
      "Processed 80000 games...\n",
      "Processed 90000 games...\n",
      "Processed 100000 games...\n",
      "Processed 110000 games...\n",
      "Processed 120000 games...\n",
      "Processed 130000 games...\n",
      "Processed 140000 games...\n",
      "Processed 150000 games...\n",
      "Processed 160000 games...\n",
      "Processed 170000 games...\n",
      "Processed 180000 games...\n",
      "Processed 190000 games...\n",
      "Processed 200000 games...\n",
      "Processed 210000 games...\n",
      "Processed 220000 games...\n",
      "Processed 230000 games...\n",
      "Processed 240000 games...\n",
      "Processed 250000 games...\n",
      "Processed 260000 games...\n",
      "Processed 270000 games...\n",
      "Processed 280000 games...\n",
      "Processed 290000 games...\n",
      "Processed 300000 games...\n",
      "Processed 310000 games...\n",
      "Processed 320000 games...\n",
      "Processed 330000 games...\n",
      "Processed 340000 games...\n",
      "Processed 350000 games...\n",
      "Processed 360000 games...\n",
      "Processed 370000 games...\n",
      "Processed 380000 games...\n",
      "Processed 390000 games...\n",
      "Processed 400000 games...\n",
      "Processed 410000 games...\n",
      "Processed 420000 games...\n",
      "Processed 430000 games...\n",
      "Processed 440000 games...\n",
      "Processed 450000 games...\n",
      "Processed 460000 games...\n",
      "Processed 470000 games...\n",
      "Processed 480000 games...\n",
      "Processed 490000 games...\n",
      "Processed 500000 games...\n",
      "Processed 510000 games...\n",
      "Processed 520000 games...\n",
      "Processed 530000 games...\n",
      "Processed 540000 games...\n",
      "Processed 550000 games...\n",
      "Processed 560000 games...\n",
      "Processed 570000 games...\n",
      "Processed 580000 games...\n",
      "Processed 590000 games...\n",
      "Processed 600000 games...\n",
      "Processed 610000 games...\n",
      "Processed 620000 games...\n",
      "Processed 630000 games...\n",
      "Processed 640000 games...\n",
      "Processed 650000 games...\n",
      "Processed 660000 games...\n",
      "Processed 670000 games...\n",
      "Processed 680000 games...\n",
      "Processed 690000 games...\n",
      "Processed 700000 games...\n",
      "Processed 710000 games...\n",
      "Processed 720000 games...\n",
      "Processed 730000 games...\n",
      "Processed 740000 games...\n",
      "Processed 750000 games...\n",
      "Processed 760000 games...\n",
      "Processed 770000 games...\n",
      "Processed 780000 games...\n",
      "Processed 790000 games...\n",
      "Processed 800000 games...\n",
      "Processed 810000 games...\n",
      "Processed 820000 games...\n",
      "Processed 830000 games...\n",
      "Processed 840000 games...\n",
      "Processed 850000 games...\n",
      "Processed 860000 games...\n",
      "Processed 870000 games...\n",
      "Processed 880000 games...\n",
      "Processed 890000 games...\n",
      "Processed 900000 games...\n",
      "Processed 910000 games...\n",
      "Processed 920000 games...\n",
      "Processed 930000 games...\n",
      "Processed 940000 games...\n",
      "Processed 950000 games...\n",
      "Processed 960000 games...\n",
      "Processed 970000 games...\n",
      "Processed 980000 games...\n",
      "Processed 990000 games...\n",
      "Processed 1000000 games...\n",
      "✅ Exported 1000000 games to games_1m.csv\n"
     ]
    }
   ],
   "source": [
    "import chess.pgn\n",
    "import pandas as pd\n",
    "\n",
    "def pgn_to_csv(pgn_file, output_csv):\n",
    "    games_data = []\n",
    "    game_count = 0\n",
    "\n",
    "    try:\n",
    "        with open(pgn_file) as f:\n",
    "            while game_count < 1000000:\n",
    "                game = chess.pgn.read_game(f)\n",
    "                if game is None:\n",
    "                    break  # End of file\n",
    "                \n",
    "                # Extract moves in SAN notation\n",
    "                board = game.board()\n",
    "                moves = []\n",
    "                for move in game.mainline_moves():\n",
    "                    san = board.san(move)\n",
    "                    moves.append(san)\n",
    "                    board.push(move)\n",
    "                \n",
    "                # Store game data\n",
    "                games_data.append({\n",
    "                    \"game_id\": game_count + 1,\n",
    "                    \"moves\": \" \".join(moves),\n",
    "                    \"num_moves\": len(moves)\n",
    "                })\n",
    "\n",
    "                game_count += 1\n",
    "                if game_count % 10000 == 0:\n",
    "                    print(f\"Processed {game_count} games...\")\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(games_data)\n",
    "\n",
    "        # Export to CSV\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ Exported {game_count} games to {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing PGN file: {e}\")\n",
    "\n",
    "# Example usage\n",
    "pgn_to_csv(\"data/lichess_db_standard_rated_2023-07.pgn\", \"games_1m.csv\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa1a90",
   "metadata": {},
   "source": [
    "# More Data Prep:\n",
    "## Creating vocab & tokenizing data, then saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2d1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('games_1m.csv')\n",
    "df = df.dropna(subset=['moves'])\n",
    "moves_list = df['moves'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7e5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vocab size: 11017\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# split games into individual moves\n",
    "tokenized_games = [s.split() for s in moves_list]\n",
    "all_moves = [move for game in tokenized_games for move in game]\n",
    "\n",
    "\n",
    "# count frequencies then sort by frequency\n",
    "move_counts = Counter(all_moves)\n",
    "unique_moves = sorted(move_counts.keys())\n",
    "\n",
    "# build vocab dictionaries\n",
    "move_to_id = {move: idx+3 for idx, move in enumerate(unique_moves)}\n",
    "id_to_move = {idx: move for move, idx in move_to_id.items()}\n",
    "\n",
    "# special tokens\n",
    "move_to_id['<PAD>'] = 0\n",
    "move_to_id['<START>'] = 1\n",
    "move_to_id['<END>'] = 2\n",
    "\n",
    "id_to_move[0] = '<PAD>'\n",
    "id_to_move[1] = '<START>'\n",
    "id_to_move[2] = '<END>'\n",
    "\n",
    "# get vocab size\n",
    "vocab_size = len(move_to_id)\n",
    "print(f\"✅ Vocab size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5088ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of moves to int ids with start, end, and padding\n",
    "def encode_game(move_list, max_len=200):\n",
    "    tokens = [move_to_id['<START>']] + [move_to_id[m] for m in move_list] + [move_to_id['<END>']]\n",
    "\n",
    "    # truncate or pad\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += [move_to_id['<PAD>']] * (max_len - len(tokens))\n",
    "    else: \n",
    "        tokens = tokens[:max_len]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "encoded_games = [encode_game(game) for game in tokenized_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361abbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\n\\n# prep for pytorch dataset\\nclass ChessDataset(Dataset):\\n    def __init__(self, encoded_tensor):\\n        self.data = encoded_tensor\\n\\n    def __len__(self):\\n        return self.data.size(0)\\n    \\n    def __getitem__(self, idx):\\n        x = self.data[idx, :-1]\\n        y = self.data[idx, 1:]\\n        return x, y\\n    \\nencoded_tensor = torch.tensor(encoded_games, dtype=torch.long)\\ndataset = ChessDataset(encoded_tensor)\\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# prep for pytorch dataset\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, encoded_tensor):\n",
    "        self.data = encoded_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx, :-1]\n",
    "        y = self.data[idx, 1:]\n",
    "        return x, y\n",
    "    \n",
    "encoded_tensor = torch.tensor(encoded_games, dtype=torch.long)\n",
    "dataset = ChessDataset(encoded_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73d4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# save vocab\n",
    "with open('move_to_id.json', 'w') as f:\n",
    "    json.dump(move_to_id, f)\n",
    "with open('id_to_move.json', 'w') as f:\n",
    "    json.dump(id_to_move, f)\n",
    "\n",
    "# save tensor\n",
    "encoded_tensor = torch.tensor(encoded_games, dtype=torch.long)\n",
    "torch.save(encoded_tensor, 'encoded_games.pt')\n",
    "\n",
    "MAX_LEN = 200\n",
    "config = {\n",
    "    'max_len': MAX_LEN,\n",
    "    'vocab_size': vocab_size,\n",
    "}\n",
    "\n",
    "with open('preprocessing_config.json', 'w') as f:\n",
    "    json.dump(config, f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56657f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example loading into separate training script\n",
    "\n",
    "'''\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Load vocab\n",
    "with open('move_to_id.json', 'r') as f:\n",
    "    move_to_id = json.load(f)\n",
    "with open('id_to_move.json', 'r') as f:\n",
    "    id_to_move = json.load(f)\n",
    "\n",
    "# Load encoded games\n",
    "encoded_tensor = torch.load('encoded_games.pt')\n",
    "\n",
    "# Load config\n",
    "with open('preprocessing_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "MAX_LEN = config['max_len']\n",
    "vocab_size = config['vocab_size']\n",
    "\n",
    "# Rebuild dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, encoded_tensor):\n",
    "        self.data = encoded_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx, :-1]\n",
    "        y = self.data[idx, 1:]\n",
    "        return x, y\n",
    "\n",
    "dataset = ChessDataset(encoded_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
